Artificial Intelligence (AI) has revolutionized the gaming industry, both as a
tool for creating intelligent in-game opponents and as a testing environment
for advancing AI research. Games serve as an ideal environment for training and
evaluating AI systems because they provide well-defined rules, measurable
objectives, and diverse challenges \cite{skinner1938}\cite{georgios2018}. 
From simple puzzles to complex strategy games, AI research in gaming has pushed 
the boundaries of machine learning and reinforcement learning 
\cite{samuel1959}\cite{minsky1961}\cite{kaelbling1996}\cite{suttonbarto2018}. 
Also, the benefits from such employment helped game developers to realize 
the power of AI methods to analyze large volumes of player data and optimize 
game designs \cite{georgios2018}. \\

Atari games, in particular, with their retro visuals and straightforward
mechanics, offer a challenging yet accessible benchmark for testing AI
algorithms. The simplicity of Atari games hides complexity: they require 
strategies that involve planning, adaptability, and fast decision-making,
making them a good testing environment for evaluating AIâ€™s ability to learn 
and generalize \cite{bellemare2013}\cite{mnih2015}. The development of AI in games 
has been a long journey, starting with rule-based systems and evolving into 
more sophisticated machine learning models \cite{samuel1959}\cite{minsky1961}. 
However, early machine learning models faced challenges in decision-making 
within interactive game environments \cite{puterman1994}\cite{howard1960}. 
Traditional supervised and unsupervised models depended on static datasets 
without the ability to interact dynamically with the environment. 
To overcome this problem, game developers and researchers began to employ 
reinforcement learning (RL) \cite{bellman1957}\cite{barto1983}\cite{sutton1988}\cite{watkins1992}\cite{dayan1992}. 
Years later, deep learning (DL) showed remarkable success in computer vision 
and video games \cite{lecun2015}\cite{goodfellow2016}\cite{I2}. The combination of RL and DL 
resulted in Deep Reinforcement Learning (DRL), enabling agents to learn directly 
from high-dimensional sensory data \cite{tsitsiklis1997}\cite{williams1992}. 
The first notable use of DRL was in Atari games \cite{I3}\cite{mnih2015}. \\

One of the leading companies in applying DRL to games is Google DeepMind. 
This company is widely recognized for developing advanced AI models, including 
those for games. Prior to AlphaGo, DeepMind had already contributed 
substantially to DRL through Atari benchmarks and novel algorithmic 
developments \cite{mnih2015}\cite{bellemare2013}. For sequential decision-making, 
DeepMind combined RL techniques with neural networks to create models capable 
of memory and reasoning, such as Neural Turing Machines (NTMs) \cite{I4}. 
They then introduced the Deep Q-Network (DQN) algorithm, which combined 
Q-learning \cite{watkins1992}\cite{watkins1989} with deep neural networks, allowing agents to 
approximate the Q-function from high-dimensional inputs \cite{I6}. 
The DQN represented a major breakthrough in deep RL, as it was the first 
algorithm to learn directly from raw pixels and achieve human-level performance 
on Atari games \cite{mnih2015}. \\

To further enhance learning efficiency, DeepMind introduced experience replay 
\cite{I7}\cite{lin1992}, which stabilized training by breaking correlations in sequential data. 
They then developed asynchronous methods such as A3C, which improved stability 
and scalability in DRL \cite{I8}\cite{konda2000}\cite{tsitsiklis1997}. These developments 
enabled DeepMind to build AlphaGo, the first AI model to defeat the world 
champion in the game of Go, a historic milestone in both AI and reinforcement 
learning \cite{Silver2016}. \\ 

Our paper is similar to Shao et al. \cite{I12}, as we discussed the 
developments that Google DeepMind made in developing AI models for 
games and the advancements that they made over the last years to develop 
the models and the future directions of implementing DRL in games; 
how this implementation helps in developing real life applications. The
main contribution in our paper is the comprehensive details of the four 
models AlphaGo, AlphaGo Zero, AlphaZero, and MuZero, focusing on the key innovations for 
each model, how the training process was done, challenges that each model
faced and the improvements that were made, and the performance benchmarks. 
Studying each one of these models in detail helps in understanding how 
RL was developed in games reaching the current state, by which it is 
now used in real life applications. Also we discussed the advancements 
in these four AI models, reaching to the future directions.
