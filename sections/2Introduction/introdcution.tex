%Introcution section%
Artificial Intelligence (AI) has revolutionized the gaming industry, 
both as a tool for creating intelligent in-game opponents and as a 
testing environment for advancing AI research. Games serve as an ideal 
environment for training and evaluating AI systems because they provide 
well-defined rules, measurable objectives, and diverse challenges. From 
simple puzzles to complex strategy games, AI research in gaming has pushed 
the boundaries of machine learning and reinforcement learning.
Also The benfits from such employment helped game developers to realize 
the power of AI methods to analyze large volumes of player data and optimize 
game designs. \cite{I1} \\
Atari games, in particular, with their retro visuals and straightforward mechanics, 
offer a challenging yet accessible benchmark for testing AI algorithms. The simplicity 
of Atari games hides complexity that they require strategies that involve planning, 
adaptability, and fast decision-making, making them also a good testing environment for 
evaluating AI's ability to learn and generalize.\\
The development of AI in games has been a long journey, starting with rule-based systems 
and evolving into more sophisticated machine learning models. However, the machine 
learning models had a few challenges, from these challenges is that the games employing 
AI involves decision making in the game evironment. Machine learning models are unable 
to interact with the decisions that the user make because it depends on learning from 
datasets and have no interaction with the environment. To overcome such problem, 
game developers started to employ reinforcement learning (RL) in developing games. 
Years later, deep learning (DL) was developed and shows remarkable results in video games\cite{I2}. 
The combination between both reinforcement learning and deep learning resulted in Deep Reinforcement 
Learning (DRL). The first employment of DRL was by game developers in atari game\cite{I3}.
One of the famous companies that employed DRL in developing AI models is Google DeepMind. 
This company is known for developing AI models, including games. Google DeepMind passed through a 
long journey in developing AI models for games. Prior to the first DRL game model they develop, 
which is AlphaGo, Google DeepMind gave a lot of contributions in developing DRL, by which these 
contributions were first employed in Atari games.\\
For the employment of DRL in games to be efficient, solving tasks in games need to be sequential, 
so Google DeepMind combined RL-like techniques with neural networks to create models capable of 
learning algorithms and solving tasks that require memory and reasoning, which is the Neural Turing 
Machines (NTMs)\cite{I4}.
They then introduced the Deep Q-network (DQN) algorithm, which is combine deep learning 
with Q-learning and RL algorithm. Q-learning is a model in reinforcement learning which use 
the Q-network, which is is a type of neural network to approximate the Q-function, which predicts 
the value of taking a particular action in a given state\cite{I5}. The DQN algorithm was the first 
algorithm that was able to learn directly from high-dimensional sensory input, the data that have a 
large number of features or dimensions\cite{I6}.\\
To enhance the speed of learning in reinforcement learning agents, Google DeepMind introduced the 
concept of experience replay, which is a technique that randomly samples previous experiences from 
the agent's memory to break the correlation between experiences and stabilize the learning process\cite{I7}. 
They then developed asynchronus methods for DRL, which is the Actor-Critic (A3C) model. This model showed 
faster and more stable training and showed a remarkable performance in Atari games\cite{I8}. By the usage of 
these algorithms, Google DeepMind was able to develop the first AI model that was able to beat the world 
champion in the game of Go, which is AlphaGo in 2016.\\ 
There are a lot of related work that reviewed the reinforcement learning in strategy-based and atari games. 
Arulkumaran et al\cite{I9} make a brief introduction of DRL, covering central algorithms and presenting a 
range of visual RL domains Zhao et al.\cite{I10} and Tang et al.\cite{I11} survey the development of DRL 
research, and focus on AlphaGo and AlphaGo Zero models. Shao et al.\cite{I12} review the development of 
DRL in game AI, from 2D to 3D, and from single-agent to multi-agent, and discuss the real-time strategy games.\\
In this paper, we will discuss the development that Google DeepMind made in developing AI models for games and 
the advancments. The main contribution will be the comparison between the three models AlphaGo, AlphaGo Zero, 
and MuZero, focusing on the challenges that each model faced and the improvements that were made. Also we will 
discuss the advancments in these three AI models, reaching to the future directions.